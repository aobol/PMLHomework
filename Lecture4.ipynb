{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c6fb08-3cea-42b3-a2e8-827f4ed02f70",
   "metadata": {},
   "source": [
    "# Lecture IV: Attention Mechanism and Network Interpretability\n",
    "\n",
    "In this homework, we will add attention mechanism to the recurrent neural network we developed in homework 3, and use it to perform network interpretability study.\n",
    "\n",
    "First, we will re-define the RNN we developed last time, starting with the module loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0530854e-4815-4698-b3a7-aaefc100077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=E1101,R,C\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import gzip\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,RobustScaler,MinMaxScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchsnooper\n",
    "from torch.cuda.amp import autocast \n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e98b4-b7e4-4bbd-9071-20ef83c290b5",
   "metadata": {},
   "source": [
    "The Japanese Vowel dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/Japanese+Vowels). For a detailed description, please look at this website. First, we will download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794b683-14a2-424a-9a0d-a95cc0184eb8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -nc https://archive.ics.uci.edu/ml/machine-learning-databases/JapaneseVowels-mld/ae.train\n",
    "!wget -nc https://archive.ics.uci.edu/ml/machine-learning-databases/JapaneseVowels-mld/ae.test\n",
    "!wget -nc https://archive.ics.uci.edu/ml/machine-learning-databases/JapaneseVowels-mld/size_ae.train\n",
    "!wget -nc https://archive.ics.uci.edu/ml/machine-learning-databases/JapaneseVowels-mld/size_ae.test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672577b-f628-42f9-8594-6ac453311a6f",
   "metadata": {},
   "source": [
    "This dataset contains 9 male japanese speaker pronouncing the utterance /ae/. The data is decoded by Linear Predictive Coding. A detail of LPC can be found [here](https://en.wikipedia.org/wiki/Linear_predictive_coding). Each utterance contains 12 LPC basis, thus for each time index, the time series will contain 12 channels.\n",
    "\n",
    "## Part I: Dataset\n",
    "\n",
    "First, we will need to prepare the dataset using `Dataset()` class. This is idential to it in homework 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed9593-fdff-4f46-b767-686586320380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JapaneseVowelDataset(Dataset):\n",
    "\n",
    "    def __init__(self,plot=True):\n",
    "        self.max_length = 29 # The maximum possible length of each utterance contains 29 samples\n",
    "        self.num_LPC = 12    # The LPC spectrum contains 12 coefficients, so the data shape will be [29,12]\n",
    "        \n",
    "        train_data, train_label = self.read_vowels(\"ae.train\",\"size_ae.train\")\n",
    "        test_data, test_label = self.read_vowels(\"ae.test\",\"size_ae.test\")\n",
    "        \n",
    "        self.size = len(train_data) + len(test_data)\n",
    "        self.train_test_split = len(train_data)\n",
    "        \n",
    "        self.data = train_data + test_data\n",
    "        self.labels = train_label + test_label\n",
    "        \n",
    "        if plot:\n",
    "            self.plot_data()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        This function returns the size of overall dataset\n",
    "        '''\n",
    "        return self.size\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        This function extract a single entry from the dataset at the given index idx\n",
    "        In this dataset, the data has variable length, so we need to pad \n",
    "        the LPC coefficients to have the same length for training purpose\n",
    "        '''\n",
    "        output = np.zeros((self.max_length, self.num_LPC))\n",
    "        data = self.data[idx]\n",
    "        output[:data.shape[0]] += data\n",
    "        return output, self.labels[idx]\n",
    "    \n",
    "    def get_train_test_split(self):\n",
    "        '''\n",
    "        This function get the train test split size of the dataset\n",
    "        '''\n",
    "        return self.train_test_split\n",
    "    \n",
    "    def read_vowels(self,file, size_file):\n",
    "        vowel_units = []\n",
    "        speaker_size = []\n",
    "        labels = []\n",
    "        #Read out the LPC value of all vowels\n",
    "        with open(file, \"r\") as f:\n",
    "            current_vowel = []\n",
    "            for line in f.readlines():\n",
    "                if line == '\\n':\n",
    "                    vowel_units.append(np.array(current_vowel))\n",
    "                    current_vowel = []\n",
    "                    continue\n",
    "                current_vowel.append(np.array(line.strip().split(\" \"),dtype=float).tolist())\n",
    "        #Read out the size of samples by 9 speakers\n",
    "        with open(size_file, \"r\") as f:\n",
    "            speaker_size = np.array(f.readline().strip().split(\" \"),dtype=int)\n",
    "            assert len(speaker_size) == 9 # If speaker size is not 9, then there's something wrong\n",
    "        #Assign a label to each speaker, speaker 1 == 0 .....speaker 9 == 8:\n",
    "        for speaker_label in range(9):\n",
    "            labels += [speaker_label] * speaker_size[speaker_label]\n",
    "        # Check if the number of label equals to number of data\n",
    "        # If not, there is something wrong\n",
    "        assert len(vowel_units) == len(labels)\n",
    "        return vowel_units, labels\n",
    "            \n",
    "                    \n",
    "        \n",
    "    \n",
    "    def plot_data(self):\n",
    "        '''\n",
    "        This function plots the LPC spectrum of 9 random utterances\n",
    "        '''\n",
    "        plt.figure(figsize=(20,12))\n",
    "        sample_index = np.random.randint(low=0,high=self.__len__(), size = 9)\n",
    "        for i in range(9):\n",
    "            plt.subplot(3,3, i+1)\n",
    "            voice, label = self.__getitem__(sample_index[i])\n",
    "            utt_length = voice.shape[0]\n",
    "            for i in range(voice.shape[-1]):\n",
    "                plt.plot(np.arange(utt_length), voice[:,i])\n",
    "            plt.xlabel(\"Time Index\")\n",
    "            plt.ylabel(\"LPC Coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c974e04-b014-4e97-bda1-caee06d0b0bb",
   "metadata": {},
   "source": [
    "Similarly, we can check the form of data by plotting the LPC spectrum coefficients. The trailing 0s comes from the padding we performed within the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279aa8a-b9d5-4cfc-82e0-1cfbbe7c6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "JapaneseVowelDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d62b0d-ccc5-4a43-8b3c-19d6f66c7a6d",
   "metadata": {},
   "source": [
    "## Part II: Recurrent Neural Network\n",
    "In this part, we will add attention mechanism to a recurrent neural network model. A typical RNN model have been provided in the following code block. You could also copy and paste your RNN from homework 3 if you prefer. Your goal is to add attention mechanism to this RNN using weight kernel concatenation:\n",
    "\\begin{equation}\n",
    "s(h_{i},h_{n})=h_{i}^{T}Wh_{n}\n",
    "\\end{equation}\n",
    "Read the RNN code carefully, try to answer two questions:\n",
    "- Why does `fc1` equal to 2 times the hidden_size of LSTM layer?\n",
    "- Why does the `self.attention_weight` tensor read a dimension of `(seq_len,hidden_size)`? How does it link back to the equation we listed above?\n",
    "\n",
    "After answering that two questions, add the attention mechanism following the procedure below:\n",
    "\n",
    "- Couple `self.attention_weight` and `output` to produce $s(h_{i},h_{n})$\n",
    "- Feed $s(h_{i},h_{n})$ into a [softmax function](https://pytorch.org/docs/master/generated/torch.nn.Softmax.html?highlight=softmax#torch.nn.Softmax) to produce attention score\n",
    "- multiply the attention score back to output to produce context vector\n",
    "- concatenate context vector with last hidden state output to produce attention vector\n",
    "- feed attention vector to the fully connected neural network\n",
    "\n",
    "Some other reference materials: \n",
    "- [lecture slide](https://drive.google.com/file/d/1-CPfeV-rA460ZS1u_cbuDyJqhn0oz5Bl/view?usp=sharing), page 28-33\n",
    "- [lecture video](https://www.youtube.com/watch?v=5C1yxV0bbSI), time 39:17-56:45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daaf391-3ef6-46ae-aafa-ddc30274416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        '''\n",
    "        Initialize RNN with attention mechanism with 3 parts:\n",
    "            A feature extractor based on LSTM network\n",
    "            A fully connected classifier\n",
    "            An attention kernel\n",
    "        '''\n",
    "        input_size = 12 #12 LPC basis per input\n",
    "        seq_len = 29    # Sequence length of Japanese Vowel data\n",
    "        hidden_size = 128\n",
    "        self.RNNLayer = torch.nn.LSTM(input_size = input_size, hidden_size = hidden_size, batch_first=True)\n",
    "        fc1, fc2, fc3, fc4 = np.linspace(hidden_size*2, 64,4,dtype=int)\n",
    "        print(fc1, fc2, fc3, fc4)\n",
    "        self.fcnet = nn.Sequential(\n",
    "            torch.nn.Linear(fc1, fc2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(fc2, fc3),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(fc3, fc4),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(fc4, 9),\n",
    "        )\n",
    "        self.attention_weight = Parameter(torch.empty(seq_len,hidden_size).uniform_(-0.1, 0.1))\n",
    "        \n",
    "#     @torchsnooper.snoop()\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        The forward operation of each training step of the neural network model\n",
    "        '''\n",
    "        output, (h, c) = self.RNNLayer(x)\n",
    "        \n",
    "        '''\n",
    "        Add attention mechanism here, you will need to code output and self.attention_weight together.\n",
    "        '''\n",
    "        \n",
    "        x = self.fcnet(attention_vector)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ef562-89de-4973-a968-dd564a6d2d6e",
   "metadata": {},
   "source": [
    "Similar to what we did in Lecture 2 homework, we will pull out 1 event from the dataset, and use `torchsnooper.snoop()` to check the network structure. Before proceeding to the next part, you may want to stare at the tensor output of `torchsnooper.snoop()` carefully to understand the tensor flow within the RNN network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f813b8e-9e76-4385-a50a-daab83da3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull out 1 event from the dataset\n",
    "test_event, test_label = next(iter(JapaneseVowelDataset(plot=False)))\n",
    "test_event = torch.FloatTensor(test_event).unsqueeze(0) # Insert batch dimension\n",
    "test_network = RNN()\n",
    "print(test_network(test_event,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1b65e-930e-4659-85fe-d494c36213fb",
   "metadata": {},
   "source": [
    "## Part III: Training and Evaluation\n",
    "After building the neural network, we train it the same way as we did in Lecture 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce807da-2b10-49fc-9c83-78e88118d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # This says if GPU is available, use GPU, otherwise use CPU\n",
    "NUM_EPOCHS =30\n",
    "LEARNING_RATE =1e-3 # 1e-2 is a good learning rate for general purpose\n",
    "BATCH_SIZE=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bbdcd-e09c-4e02-bd04-b9214d5f9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_classifier():\n",
    "    classifier = RNN() # Define CNN neural network classifier\n",
    "    classifier.to(DEVICE)     # Send the classifier to DEVICE as we defined earlier\n",
    "\n",
    "    print(\"# of params in model: \", sum(x.numel() for x in classifier.parameters()))\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(DEVICE)\n",
    "\n",
    "    #Define the optimizer\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(),lr=LEARNING_RATE)\n",
    "    \n",
    "    return classifier, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4c371-4de8-4a45-9ce3-03735bdfdab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader():\n",
    "    dataset = JapaneseVowelDataset(plot=False)\n",
    "    #Get the indices of train dataset and test dataset correspondingly, indices [0:train_test_split] is the training dataset, indices [train_test_split, len(dataset)] is the test dataset.\n",
    "    train_test_split = dataset.get_train_test_split()\n",
    "    train_indices, val_indices = list(range(train_test_split)), list(range(train_test_split,len(dataset)))\n",
    "\n",
    "    #Shuffle the two indices list\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(val_indices)\n",
    "\n",
    "    # Define two subset random sampler to sample events according to the training indices\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    # Finally, define the loader by passing in the dataset, batch size and corresponding sampler\n",
    "    # Note that the number of data in each sub-dataset might not be divisibe by the batch size, so drop_last=True drops the last batch with all the residual events.\n",
    "    train_loader = data_utils.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler, drop_last=True)\n",
    "    test_loader = data_utils.DataLoader(dataset, batch_size=BATCH_SIZE,sampler=valid_sampler,  drop_last=True)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146fbea3-f699-491d-b524-2a5c3925f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, criterion, optimizer = set_up_classifier()\n",
    "train_loader, test_loader = get_dataloader()\n",
    "\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (utterances, labels) in tqdm(enumerate(train_loader)):\n",
    "        classifier.train() # This line set the neural network to train mode, some layers perform differently in train and test mode.\n",
    "        \n",
    "        utterances = utterances.to(DEVICE).float()\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        #Train the RNN classifier\n",
    "        outputs  = classifier(utterances)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Back-propagate loss to update gradient\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform gradient descent to update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # reset gradient to 0 on all parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print('\\rEpoch [{0}/{1}], Iter [{2}/{3}] Loss: {4:.4f}'.format(\n",
    "        epoch+1, NUM_EPOCHS, i+1, len(train_loader),\n",
    "        loss.item(), end=\"\"),end=\"\")\n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    #After every epoch, evaluate the validation accuracy on the test loader\n",
    "    num_accurate = 0\n",
    "    num_images = 0\n",
    "    for utterances,labels in tqdm(test_loader):\n",
    "\n",
    "        classifier.eval() # This line set the neural network to evaluation mode, some layers perform differently in train and test mode.\n",
    "        \n",
    "        #While validating the network, we do not want it to produce any gradient. This will also save us time/memory\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Convey images to device, then feed it to the neural network for network output\n",
    "            utterances = utterances.to(DEVICE).float()\n",
    "            outputs  = classifier(utterances)\n",
    "            \n",
    "            # Get classification decision by reading out the maximum value on the 10-dimensional vector\n",
    "            decision = torch.argmax(outputs, dim=-1)\n",
    "            decision = decision.cpu().data.numpy().flatten() # copy decision to CPU and convert it to a numpy array\n",
    "            labels = labels.cpu().data.numpy().flatten()\n",
    "            \n",
    "            # Update the list of truth value and network predictions in last epoch:\n",
    "            if epoch == (NUM_EPOCHS-1):\n",
    "                y_true += list(labels)\n",
    "                y_pred += list(decision)\n",
    "            \n",
    "            #Calculate accuracy by # of correct prediction / total numbers\n",
    "\n",
    "            num_accurate += np.sum((decision - labels) == 0)\n",
    "            num_images += len(decision)\n",
    "    accuracy_values.append(num_accurate/num_images)  \n",
    "torch.save(classifier.state_dict(), 'RNN.pt') # Save the trained RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343a1f4-6670-4777-ac08-17ace1fe8079",
   "metadata": {},
   "source": [
    "After training, we will be able to evaluate our training results.\n",
    "\n",
    "First, let's plot the learning curve, that is, the loss value with respect to the epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a3073-822f-42f0-b298-c77b9c99c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(NUM_EPOCHS).astype(int), loss_values)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross Entropy Loss [a.u.]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e134676-4538-47ba-82ef-efb065368368",
   "metadata": {},
   "source": [
    "You should find that the loss drops as you train the network with more and more epochs.\n",
    "\n",
    "Next, let's plot the accuracy curve. That is, the accuracy with respect to epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143075c-783a-4f7b-ab58-477c80178d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(NUM_EPOCHS).astype(int), np.array(accuracy_values)*100.0)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Classification Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e5b65-aaa5-4e38-904f-6eab58cae9d6",
   "metadata": {},
   "source": [
    "Does the training result gets better than the RNN in lecture 3 homework? If not, the reason might be:\n",
    "- The dataset is too small\n",
    "- The task is too easy to attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f66c6-7953-4612-9669-4d1c2d6fa67f",
   "metadata": {},
   "source": [
    "## Part IV: RNN Interpretability\n",
    "\n",
    "Network interpretability refers to the capability to explain each decision of the neural network. A traditional neural network model is black-box, meaning that we do not know which one or many features it utilize to make the classification decision. The beauty of attention mechanism is that: it provides us a straightforward way to interpret the decision of RNN or transformer network. In this part, we will leverage the attention score to find the origin of RNN classification power.\n",
    "\n",
    "First, we will need to do some tweakings of the RNN neural network. In the following code block, copy/paste the RNN model you defined previously, and change the output from `x` to the attention score variable. Remember that the attention score is the output of softmax operation. What is the shape of the attention score? You can check it using torchsnooper.\n",
    "\n",
    "**Notice**: Do not change anything in the `__init__` method, otherwise the neural network may fail loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c31908-605f-4837-beb1-47e03870f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNInterpretor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNInterpretor, self).__init__()\n",
    "        '''\n",
    "        Initialize RNN with attention mechanism with 3 parts:\n",
    "            A feature extractor based on LSTM network\n",
    "            A fully connected classifier\n",
    "            An attention kernel\n",
    "        '''\n",
    "        input_size = 12 #12 LPC basis per input\n",
    "        seq_len = 29    # Sequence length of Japanese Vowel data\n",
    "        hidden_size = 128\n",
    "        self.RNNLayer = torch.nn.LSTM(input_size = input_size, hidden_size = hidden_size, batch_first=True)\n",
    "        fc1, fc2, fc3, fc4 = np.linspace(hidden_size*2, 64,4,dtype=int)\n",
    "        self.fcnet = nn.Sequential(\n",
    "            torch.nn.Linear(fc1, fc2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(fc2, fc3),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(fc3, fc4),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(fc4, 9),\n",
    "        )\n",
    "        self.attention_weight = Parameter(torch.empty(seq_len,hidden_size).uniform_(-0.1, 0.1))\n",
    "        \n",
    "#     @torchsnooper.snoop()\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        The forward operation of each training step of the neural network model\n",
    "        '''\n",
    "        output, (h, c) = self.RNNLayer(x)\n",
    "        \n",
    "        '''\n",
    "        Add attention mechanism here, you will need to code output and self.attention_weight together.\n",
    "        '''\n",
    "        \n",
    "        x = self.fcnet(attention_vector)\n",
    "        return attention_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c03c5-9c9d-4622-b0f6-5cc3547efef7",
   "metadata": {},
   "source": [
    "Then, we will load the parameters we saved from the trained RNN to build an interpretor network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc22f6-77b0-40dc-a810-8525451ff611",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretor = RNNInterpretor()\n",
    "pretrained_dict = torch.load('RNN.pt')\n",
    "model_dict = interpretor.state_dict()\n",
    "model_dict.update(pretrained_dict) \n",
    "interpretor.load_state_dict(pretrained_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f4dfb-10ad-4f6f-a260-38b7c9cf0f97",
   "metadata": {},
   "source": [
    "Then, we will pull out a batch of event from the test loader and plot its attention score. The attention score refects the relative importance of each time slices. Since attention score will sum to 1, it can also be treated as the relative weight of each time slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e037e3-44ce-460e-b00d-6a3f7db6853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Feed event through the interpretor to get attention score\n",
    "test_event, test_label = next(iter(test_loader))\n",
    "test_event = test_event.to(DEVICE).float()\n",
    "attention_score = interpretor(test_event)\n",
    "#############################################\n",
    "\n",
    "interpretor.eval()\n",
    "batch_size = len(test_label)\n",
    "fig = plt.figure(figsize=(40,40))\n",
    "cellc = int(math.ceil((batch_size**0.5)))\n",
    "outer = gridspec.GridSpec(cellc, cellc, wspace=0.2, hspace=0.2)\n",
    "for i in range(batch_size):\n",
    "    inner = gridspec.GridSpecFromSubplotSpec(2, 1,subplot_spec=outer[i], wspace=0.1, hspace=0.1, height_ratios=[5,1])\n",
    "    attention = torch.sum(attention_score[i],dim=-1).cpu().data.numpy().flatten() # The last dimension of attention score is the hidden size (128) in default case, we will sum over this dimension to get the attention score for this time inde\n",
    "    attention -= np.average(attention) # Only plot the variance of attention to see trends\n",
    "    current_vowel = test_event[i]\n",
    "    \n",
    "    ax_main = plt.Subplot(fig, inner[0])\n",
    "    vowel_length, lpc_basis = current_vowel.shape\n",
    "    for j in range(lpc_basis):\n",
    "        ax_main.plot(np.arange(vowel_length), current_vowel[:,j])\n",
    "    ax_main.legend()\n",
    "    fig.add_subplot(ax_main)\n",
    "\n",
    "    ax_attention = plt.Subplot(fig, inner[1], sharex=ax_main)\n",
    "    ax_attention.bar(x=np.arange(vowel_length)+0.5,height=attention, width=1)\n",
    "    fig.add_subplot(ax_attention)\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e661e5d-9483-4af2-b2cb-698c7d6dab8e",
   "metadata": {},
   "source": [
    "**Question:** How does the attention score reflects the classification power of RNN? Since we perform 0 embedding onto the data to make them equal in length, all input should contain several 0s towards the end. Does this 0-embedded region exhibit high attention score? In other words, does the RNN classifier pay attention to the embedded 0s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8afbd81-eb86-4b82-b8ba-5c00cb0303d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
